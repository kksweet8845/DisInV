{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing, model_selection, feature_extraction, naive_bayes, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Json to csv\n",
    "def json2df(json_obj):\n",
    "    \n",
    "    ls = []\n",
    "    for row in json_obj:\n",
    "        ls.append([\n",
    "            row['title'],\n",
    "            row['content'],\n",
    "            row['author'],\n",
    "            row['brand_id'],\n",
    "            row['date'],\n",
    "            row['url']\n",
    "        ])\n",
    "    \n",
    "    col = [\n",
    "            'title',\n",
    "            'content',\n",
    "            'author',\n",
    "            'date',\n",
    "            'url',\n",
    "            'brand_id'\n",
    "        ]\n",
    "    \n",
    "    return pd.DataFrame(ls, columns=col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataset\n",
    "\n",
    "## Read news\n",
    "with open('./data/real_news_dump.json') as file:\n",
    "    real_news = json.load(file)\n",
    "\n",
    "real_news_df = json2df(real_news)\n",
    "\n",
    "## Fake news\n",
    "with open('./data/fake_news_dump.json') as file:\n",
    "    fake_news = json.load(file)\n",
    "    \n",
    "fake_news_df = json2df(fake_news)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# label dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label real dataset\n",
    "real_label = [True]*len(real_news_df)\n",
    "real_news_df['label'] = real_label\n",
    "real_news_df = real_news_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(real_news_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label fake dataset\n",
    "fake_label = [False]*len(fake_news_df)\n",
    "fake_news_df['label'] = fake_label\n",
    "fake_news_df = fake_news_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "674"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fake_news_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compact\n",
    "compact_df = pd.concat([real_news_df, fake_news_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, y\n",
    "X = compact_df['title']\n",
    "y = compact_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfidf',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, use_idf=True,\n",
       "                                 vocabulary=None)),\n",
       "                ('clf',\n",
       "                 BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None,\n",
       "                             fit_prior=True))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "text_clf = Pipeline([\n",
    "    ('tfidf', feature_extraction.text.TfidfVectorizer()),\n",
    "    ('clf', naive_bayes.BernoulliNB())\n",
    "])\n",
    "text_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "pred = text_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6157517899761337"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(pred == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.00      0.00      0.00       161\n",
      "        True       0.62      1.00      0.76       258\n",
      "\n",
      "    accuracy                           0.62       419\n",
      "   macro avg       0.31      0.50      0.38       419\n",
      "weighted avg       0.38      0.62      0.47       419\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, pred, target_names=['False', 'True']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[258,   0],\n",
       "       [161,   0]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_test, pred, labels=[True, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "419"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfidf',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='...\n",
       "                 SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "                               early_stopping=False, epsilon=0.1, eta0=0.0,\n",
       "                               fit_intercept=True, l1_ratio=0.15,\n",
       "                               learning_rate='optimal', loss='hinge',\n",
       "                               max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
       "                               penalty='l2', power_t=0.5, random_state=None,\n",
       "                               shuffle=True, tol=0.001, validation_fraction=0.1,\n",
       "                               verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "text_clf = Pipeline([\n",
    "    ('tfidf', feature_extraction.text.TfidfVectorizer()),\n",
    "    ('clf', SGDClassifier())\n",
    "])\n",
    "text_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "pred = text_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8305489260143198"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(pred == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.70      0.99      0.82       161\n",
      "        True       0.99      0.73      0.84       258\n",
      "\n",
      "    accuracy                           0.83       419\n",
      "   macro avg       0.85      0.86      0.83       419\n",
      "weighted avg       0.88      0.83      0.83       419\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, pred, target_names=['False', 'True']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 0.4486873508353222, TN: 0.3818615751789976, FP: 0.16706443914081145, FN:0.002386634844868735\n"
     ]
    }
   ],
   "source": [
    "TP, TN, FP, FN = ([], [], [], [])\n",
    "for i in range(len(pred)):\n",
    "    # TP\n",
    "    if y_test.iloc[i] == True and pred[i] == True:\n",
    "        TP.append(i)\n",
    "    # TN\n",
    "    if y_test.iloc[i] == False and pred[i] == False:\n",
    "        TN.append(i)\n",
    "    # FP\n",
    "    if y_test.iloc[i] == True and pred[i] == False:\n",
    "        FP.append(i)\n",
    "    # FN\n",
    "    if y_test.iloc[i] == False and pred[i] == True:\n",
    "        FN.append(i)\n",
    "print('TP: {}, TN: {}, FP: {}, FN:{}'.format(len(TP)/len(pred), len(TN)/len(pred), len(FP)/len(pred), len(FN)/len(pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1129    加州／舊金山／台灣政府要求戴口罩，但是沒有要求要穿衣服\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.iloc[FN]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfidf',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, use_idf=True,\n",
       "                                 vocabulary=None)),\n",
       "                ('clf',\n",
       "                 AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
       "                                    learning_rate=1.0, n_estimators=50,\n",
       "                                    random_state=None))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "text_clf = Pipeline([\n",
    "    ('tfidf', feature_extraction.text.TfidfVectorizer()),\n",
    "    ('clf', AdaBoostClassifier())\n",
    "])\n",
    "text_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "pred = text_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7279236276849642"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(pred == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.59      1.00      0.74       161\n",
      "        True       1.00      0.56      0.72       258\n",
      "\n",
      "    accuracy                           0.73       419\n",
      "   macro avg       0.79      0.78      0.73       419\n",
      "weighted avg       0.84      0.73      0.72       419\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, pred, target_names=['False', 'True']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 0.3436754176610978, TN: 0.38424821002386633, FP: 0.2720763723150358, FN:0.0\n"
     ]
    }
   ],
   "source": [
    "TP, TN, FP, FN = ([], [], [], [])\n",
    "for i in range(len(pred)):\n",
    "    # TP\n",
    "    if y_test.iloc[i] == True and pred[i] == True:\n",
    "        TP.append(i)\n",
    "    # TN\n",
    "    if y_test.iloc[i] == False and pred[i] == False:\n",
    "        TN.append(i)\n",
    "    # FP\n",
    "    if y_test.iloc[i] == True and pred[i] == False:\n",
    "        FP.append(i)\n",
    "    # FN\n",
    "    if y_test.iloc[i] == False and pred[i] == True:\n",
    "        FN.append(i)\n",
    "print('TP: {}, TN: {}, FP: {}, FN:{}'.format(len(TP)/len(pred), len(TN)/len(pred), len(FP)/len(pred), len(FN)/len(pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfidf',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='...b',\n",
       "                                 tokenizer=None, use_idf=True,\n",
       "                                 vocabulary=None)),\n",
       "                ('clf',\n",
       "                 DecisionTreeClassifier(class_weight=None, criterion='gini',\n",
       "                                        max_depth=None, max_features=None,\n",
       "                                        max_leaf_nodes=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=1, min_samples_split=2,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        presort=False, random_state=None,\n",
       "                                        splitter='best'))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "text_clf = Pipeline([\n",
    "    ('tfidf', feature_extraction.text.TfidfVectorizer()),\n",
    "    ('clf', DecisionTreeClassifier())\n",
    "])\n",
    "text_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "pred = text_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8257756563245824"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(pred == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.69      1.00      0.82       161\n",
      "        True       1.00      0.72      0.84       258\n",
      "\n",
      "    accuracy                           0.83       419\n",
      "   macro avg       0.84      0.86      0.83       419\n",
      "weighted avg       0.88      0.83      0.83       419\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, pred, target_names=['False', 'True']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 0.441527446300716, TN: 0.38424821002386633, FP: 0.17422434367541767, FN:0.0\n"
     ]
    }
   ],
   "source": [
    "TP, TN, FP, FN = ([], [], [], [])\n",
    "for i in range(len(pred)):\n",
    "    # TP\n",
    "    if y_test.iloc[i] == True and pred[i] == True:\n",
    "        TP.append(i)\n",
    "    # TN\n",
    "    if y_test.iloc[i] == False and pred[i] == False:\n",
    "        TN.append(i)\n",
    "    # FP\n",
    "    if y_test.iloc[i] == True and pred[i] == False:\n",
    "        FP.append(i)\n",
    "    # FN\n",
    "    if y_test.iloc[i] == False and pred[i] == True:\n",
    "        FN.append(i)\n",
    "print('TP: {}, TN: {}, FP: {}, FN:{}'.format(len(TP)/len(pred), len(TN)/len(pred), len(FP)/len(pred), len(FN)/len(pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nober/Py3.6m/lib/python3.6/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfidf',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='...\n",
       "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                        criterion='gini', max_depth=None,\n",
       "                                        max_features='auto',\n",
       "                                        max_leaf_nodes=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=1, min_samples_split=2,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        n_estimators=10, n_jobs=None,\n",
       "                                        oob_score=False, random_state=None,\n",
       "                                        verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "text_clf = Pipeline([\n",
    "    ('tfidf', feature_extraction.text.TfidfVectorizer()),\n",
    "    ('clf', RandomForestClassifier())\n",
    "])\n",
    "text_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "pred = text_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7995226730310262"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(pred == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.66      1.00      0.79       161\n",
      "        True       1.00      0.67      0.81       258\n",
      "\n",
      "    accuracy                           0.80       419\n",
      "   macro avg       0.83      0.84      0.80       419\n",
      "weighted avg       0.87      0.80      0.80       419\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, pred, target_names=['False', 'True']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 174, TN: 161, FP: 84, FN:0\n"
     ]
    }
   ],
   "source": [
    "TP, TN, FP, FN = ([], [], [], [])\n",
    "for i in range(len(pred)):\n",
    "    # TP\n",
    "    if y_test.iloc[i] == True and pred[i] == True:\n",
    "        TP.append(i)\n",
    "    # TN\n",
    "    if y_test.iloc[i] == False and pred[i] == False:\n",
    "        TN.append(i)\n",
    "    # FP\n",
    "    if y_test.iloc[i] == True and pred[i] == False:\n",
    "        FP.append(i)\n",
    "    # FN\n",
    "    if y_test.iloc[i] == False and pred[i] == True:\n",
    "        FN.append(i)\n",
    "print('TP: {}, TN: {}, FP: {}, FN:{}'.format(len(TP), len(TN), len(FP), len(FN)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ComplementNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfidf',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, use_idf=True,\n",
       "                                 vocabulary=None)),\n",
       "                ('clf',\n",
       "                 ComplementNB(alpha=1.0, class_prior=None, fit_prior=True,\n",
       "                              norm=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "text_clf = Pipeline([\n",
    "    ('tfidf', feature_extraction.text.TfidfVectorizer()),\n",
    "    ('clf', ComplementNB())\n",
    "])\n",
    "text_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "pred = text_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8305489260143198"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(pred == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.70      0.99      0.82       161\n",
      "        True       0.99      0.73      0.84       258\n",
      "\n",
      "    accuracy                           0.83       419\n",
      "   macro avg       0.85      0.86      0.83       419\n",
      "weighted avg       0.88      0.83      0.83       419\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, pred, target_names=['False', 'True']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 0.4486873508353222, TN: 0.3818615751789976, FP: 0.16706443914081145, FN:0.002386634844868735\n"
     ]
    }
   ],
   "source": [
    "TP, TN, FP, FN = ([], [], [], [])\n",
    "for i in range(len(pred)):\n",
    "    # TP\n",
    "    if y_test.iloc[i] == True and pred[i] == True:\n",
    "        TP.append(i)\n",
    "    # TN\n",
    "    if y_test.iloc[i] == False and pred[i] == False:\n",
    "        TN.append(i)\n",
    "    # FP\n",
    "    if y_test.iloc[i] == True and pred[i] == False:\n",
    "        FP.append(i)\n",
    "    # FN\n",
    "    if y_test.iloc[i] == False and pred[i] == True:\n",
    "        FN.append(i)\n",
    "print('TP: {}, TN: {}, FP: {}, FN:{}'.format(len(TP)/len(pred), len(TN)/len(pred), len(FP)/len(pred), len(FN)/len(pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
